<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>
  <head>
    <title>Measurement Bias in Performance Evaluation</title>
  </head>

  <body>
    <h1>Measurement Bias in Performance Evaluation</h1>
To evaluate an innovation in computer systems, performance analysts
measure execution time or other metrics using one or more standard
workloads. The performance analyst may carefully minimize the amount
of measurement instrumentation, control the environment in which
measurement takes place, and repeat each measurement multiple
times. Finally, the performance analyst may use statistical techniques
to characterize the data.
<p>
Unfortunately even with such a responsible approach, the data a
performance analyst collects may be misleading.  This talk details how
easy it is to produce poor (and thus misleading) data for computer
systems research because of the pervasiveness of measurement bias.
Measurement bias occurs when a particular environment in which the
measurement takes place favors one configuration over others. This
talk demonstrates that measurement bias has a significant impact on
performance and if ignored, can easily lead a performance analyst to
an incorrect conclusion.
<p>
We conclude by describing techniques that help a performance analyst
identify and ultimately correct situations when they have poor quality
data.


    <hr>
    <address><a href="mailto:Todd.Mytkowicz@colorado.edu">Todd Mytkowicz</a></address>
<!-- Created: Mon Mar 24 14:12:12 MDT 2008 -->
<!-- hhmts start -->
Last modified: Tue Apr  8 12:26:46 MDT 2008
<!-- hhmts end -->
  </body>
</html>
